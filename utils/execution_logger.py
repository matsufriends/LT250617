"""
å®Ÿè¡Œãƒ­ã‚°è¨˜éŒ²ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - åˆ†æç”¨ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½
"""

import json
import os
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

from config import JSON_INDENT_LEVEL


class ExecutionLogger:
    """å®Ÿè¡Œãƒ­ã‚°ã‚’è¨˜éŒ²ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, cache_dir: str = "cache"):
        """
        åˆæœŸåŒ–
        
        Args:
            cache_dir: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # å®Ÿè¡Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹
        self.session_start = datetime.now()
        self.session_id = self.session_start.strftime("%Y%m%d_%H%M%S")
        
        # ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
        self.execution_log = {
            "session_id": self.session_id,
            "session_start": self.session_start.isoformat(),
            "character_name": None,
            "steps": [],
            "api_calls": [],
            "errors": [],
            "performance": {},
            "final_result": None
        }
    
    def set_character_name(self, name: str):
        """å‡¦ç†å¯¾è±¡ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’è¨­å®š"""
        self.execution_log["character_name"] = name
    
    def log_step(self, step_name: str, status: str, details: Dict[str, Any] = None, duration: float = None):
        """
        å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        
        Args:
            step_name: ã‚¹ãƒ†ãƒƒãƒ—å
            status: å®Ÿè¡ŒçŠ¶æ…‹ (start, success, error, info)
            details: è©³ç´°æƒ…å ±
            duration: å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
        """
        step_data = {
            "timestamp": datetime.now().isoformat(),
            "step_name": step_name,
            "status": status,
            "details": details or {},
            "duration": duration
        }
        
        self.execution_log["steps"].append(step_data)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ä¿å­˜
        self._save_log()
    
    def log_api_call(self, api_type: str, request_data: Dict[str, Any], response_data: Dict[str, Any], 
                     duration: float = None, error: str = None):
        """
        APIå‘¼ã³å‡ºã—ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        
        Args:
            api_type: APIç¨®åˆ¥ (openai, wikipedia, google, youtube)
            request_data: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            response_data: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
            duration: å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
            error: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        """
        api_call_data = {
            "timestamp": datetime.now().isoformat(),
            "api_type": api_type,
            "request": request_data,
            "response": response_data,
            "duration": duration,
            "error": error,
            "status": "error" if error else "success"
        }
        
        self.execution_log["api_calls"].append(api_call_data)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ä¿å­˜
        self._save_log()
    
    def log_error(self, error_type: str, error_message: str, context: Dict[str, Any] = None):
        """
        ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        
        Args:
            error_type: ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥
            error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            context: ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        error_data = {
            "timestamp": datetime.now().isoformat(),
            "error_type": error_type,
            "error_message": error_message,
            "context": context or {}
        }
        
        self.execution_log["errors"].append(error_data)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ä¿å­˜
        self._save_log()
    
    def log_performance_metric(self, metric_name: str, value: Any, unit: str = None):
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        
        Args:
            metric_name: æŒ‡æ¨™å
            value: å€¤
            unit: å˜ä½
        """
        self.execution_log["performance"][metric_name] = {
            "value": value,
            "unit": unit,
            "timestamp": datetime.now().isoformat()
        }
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ä¿å­˜
        self._save_log()
    
    def set_final_result(self, result: Dict[str, Any]):
        """
        æœ€çµ‚çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        
        Args:
            result: æœ€çµ‚çµæœãƒ‡ãƒ¼ã‚¿
        """
        self.execution_log["final_result"] = result
        self.execution_log["session_end"] = datetime.now().isoformat()
        
        # æœ€çµ‚ä¿å­˜
        self._save_log()
    
    def _save_log(self):
        """ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¥ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
            log_file = self.cache_dir / f"execution_log_{self.session_id}.json"
            
            # ãƒ­ã‚°ä¿å­˜æ™‚ã®é€²æ—ã‚’è¡¨ç¤º
            print(f"  ğŸ’¾ ãƒ­ã‚°æ›´æ–°ä¸­: {log_file.name}")
            
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(self.execution_log, f, ensure_ascii=False, indent=JSON_INDENT_LEVEL)
                f.flush()  # å¼·åˆ¶çš„ã«ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
                os.fsync(f.fileno())  # OSãƒ¬ãƒ™ãƒ«ã§ã®æ›¸ãè¾¼ã¿å¼·åˆ¶
            
            # æœ€æ–°ãƒ­ã‚°ã®ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯çš„ãªå½¹å‰²
            latest_log_file = self.cache_dir / "latest_execution_log.json"
            with open(latest_log_file, 'w', encoding='utf-8') as f:
                json.dump(self.execution_log, f, ensure_ascii=False, indent=JSON_INDENT_LEVEL)
                f.flush()  # å¼·åˆ¶çš„ã«ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
                os.fsync(f.fileno())  # OSãƒ¬ãƒ™ãƒ«ã§ã®æ›¸ãè¾¼ã¿å¼·åˆ¶
                
        except Exception as e:
            print(f"âš ï¸ ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_summary(self) -> Dict[str, Any]:
        """å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        total_steps = len(self.execution_log["steps"])
        successful_steps = len([s for s in self.execution_log["steps"] if s["status"] == "success"])
        total_api_calls = len(self.execution_log["api_calls"])
        successful_api_calls = len([a for a in self.execution_log["api_calls"] if a["status"] == "success"])
        total_errors = len(self.execution_log["errors"])
        
        session_duration = None
        if "session_end" in self.execution_log:
            start_time = datetime.fromisoformat(self.execution_log["session_start"])
            end_time = datetime.fromisoformat(self.execution_log["session_end"])
            session_duration = (end_time - start_time).total_seconds()
        
        return {
            "session_id": self.session_id,
            "character_name": self.execution_log["character_name"],
            "total_steps": total_steps,
            "successful_steps": successful_steps,
            "total_api_calls": total_api_calls,
            "successful_api_calls": successful_api_calls,
            "total_errors": total_errors,
            "session_duration": session_duration,
            "performance_metrics": self.execution_log["performance"]
        }


class ExecutionLogAnalyzer:
    """å®Ÿè¡Œãƒ­ã‚°ã®åˆ†æã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, cache_dir: str = "cache"):
        """
        åˆæœŸåŒ–
        
        Args:
            cache_dir: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        """
        self.cache_dir = Path(cache_dir)
    
    def load_log(self, session_id: str = None) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆNoneã®å ´åˆã¯æœ€æ–°ãƒ­ã‚°ï¼‰
            
        Returns:
            ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
        """
        try:
            if session_id:
                log_file = self.cache_dir / f"execution_log_{session_id}.json"
            else:
                log_file = self.cache_dir / "latest_execution_log.json"
            
            if log_file.exists():
                with open(log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {}
                
        except Exception as e:
            print(f"âš ï¸ ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def list_all_sessions(self) -> List[str]:
        """å…¨ã¦ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’å–å¾—"""
        try:
            session_ids = []
            for log_file in self.cache_dir.glob("execution_log_*.json"):
                session_id = log_file.stem.replace("execution_log_", "")
                session_ids.append(session_id)
            
            return sorted(session_ids, reverse=True)  # æ–°ã—ã„é †
            
        except Exception as e:
            print(f"âš ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def analyze_api_performance(self, session_id: str = None) -> Dict[str, Any]:
        """
        APIå‘¼ã³å‡ºã—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æ
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆNoneã®å ´åˆã¯æœ€æ–°ãƒ­ã‚°ï¼‰
            
        Returns:
            åˆ†æçµæœ
        """
        log_data = self.load_log(session_id)
        if not log_data or "api_calls" not in log_data:
            return {}
        
        api_calls = log_data["api_calls"]
        
        analysis = {
            "total_calls": len(api_calls),
            "successful_calls": len([c for c in api_calls if c["status"] == "success"]),
            "failed_calls": len([c for c in api_calls if c["status"] == "error"]),
            "by_api_type": {},
            "average_duration": {}
        }
        
        # APIç¨®åˆ¥ã”ã¨ã®çµ±è¨ˆ
        for call in api_calls:
            api_type = call["api_type"]
            if api_type not in analysis["by_api_type"]:
                analysis["by_api_type"][api_type] = {
                    "total": 0,
                    "successful": 0,
                    "failed": 0,
                    "durations": []
                }
            
            analysis["by_api_type"][api_type]["total"] += 1
            if call["status"] == "success":
                analysis["by_api_type"][api_type]["successful"] += 1
            else:
                analysis["by_api_type"][api_type]["failed"] += 1
            
            if call["duration"]:
                analysis["by_api_type"][api_type]["durations"].append(call["duration"])
        
        # å¹³å‡å®Ÿè¡Œæ™‚é–“è¨ˆç®—
        for api_type, data in analysis["by_api_type"].items():
            if data["durations"]:
                analysis["average_duration"][api_type] = sum(data["durations"]) / len(data["durations"])
        
        return analysis
    
    def analyze_character_extraction_quality(self, session_id: str = None) -> Dict[str, Any]:
        """
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºå“è³ªã‚’åˆ†æ
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆNoneã®å ´åˆã¯æœ€æ–°ãƒ­ã‚°ï¼‰
            
        Returns:
            å“è³ªåˆ†æçµæœ
        """
        log_data = self.load_log(session_id)
        if not log_data:
            return {}
        
        # æœ€çµ‚çµæœã‹ã‚‰å“è³ªæŒ‡æ¨™ã‚’æŠ½å‡º
        final_result = log_data.get("final_result")
        if not final_result:
            return {}
        
        quality_metrics = {}
        
        # Wikipediaæƒ…å ±ã®å“è³ª
        if "wikipedia_info" in final_result:
            wiki_info = final_result["wikipedia_info"]
            quality_metrics["wikipedia"] = {
                "found": wiki_info.get("found", False),
                "summary_length": len(wiki_info.get("summary", "")),
                "has_categories": bool(wiki_info.get("categories"))
            }
        
        # Googleæ¤œç´¢çµæœã®å“è³ª
        if "google_search_results" in final_result:
            google_info = final_result["google_search_results"]
            quality_metrics["google"] = {
                "total_results": google_info.get("total_results", 0),
                "speech_patterns_found": sum(len(result.get("speech_patterns", [])) 
                                           for result in google_info.get("results", []))
            }
        
        # YouTubeæƒ…å ±ã®å“è³ª
        if "youtube_transcripts" in final_result:
            youtube_info = final_result["youtube_transcripts"]
            quality_metrics["youtube"] = {
                "videos_processed": youtube_info.get("total_videos", 0),
                "sample_phrases_count": len(youtube_info.get("sample_phrases", [])),
                "successful_extractions": youtube_info.get("successful_extractions", 0)
            }
        
        return quality_metrics
    
    def generate_analysis_report(self, session_id: str = None) -> str:
        """
        è©³ç´°ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆNoneã®å ´åˆã¯æœ€æ–°ãƒ­ã‚°ï¼‰
            
        Returns:
            åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰
        """
        log_data = self.load_log(session_id)
        if not log_data:
            return "ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        
        # åŸºæœ¬æƒ…å ±
        character_name = log_data.get("character_name", "ä¸æ˜")
        session_start = log_data.get("session_start", "ä¸æ˜")
        session_end = log_data.get("session_end", "å®Ÿè¡Œä¸­")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        api_analysis = self.analyze_api_performance(session_id)
        quality_analysis = self.analyze_character_extraction_quality(session_id)
        
        report_lines = [
            f"=== å®Ÿè¡Œãƒ­ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ===",
            f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å: {character_name}",
            f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {log_data.get('session_id', 'ä¸æ˜')}",
            f"é–‹å§‹æ™‚åˆ»: {session_start}",
            f"çµ‚äº†æ™‚åˆ»: {session_end}",
            "",
            "=== APIå‘¼ã³å‡ºã—çµ±è¨ˆ ===",
            f"ç·APIå‘¼ã³å‡ºã—æ•°: {api_analysis.get('total_calls', 0)}",
            f"æˆåŠŸ: {api_analysis.get('successful_calls', 0)}",
            f"å¤±æ•—: {api_analysis.get('failed_calls', 0)}",
            ""
        ]
        
        # APIç¨®åˆ¥ã”ã¨ã®è©³ç´°
        if "by_api_type" in api_analysis:
            report_lines.append("=== APIç¨®åˆ¥ã”ã¨ã®çµ±è¨ˆ ===")
            for api_type, stats in api_analysis["by_api_type"].items():
                avg_duration = api_analysis.get("average_duration", {}).get(api_type, 0)
                report_lines.extend([
                    f"{api_type}:",
                    f"  - å‘¼ã³å‡ºã—æ•°: {stats['total']}",
                    f"  - æˆåŠŸç‡: {stats['successful']}/{stats['total']}",
                    f"  - å¹³å‡å®Ÿè¡Œæ™‚é–“: {avg_duration:.2f}ç§’",
                    ""
                ])
        
        # å“è³ªåˆ†æ
        if quality_analysis:
            report_lines.append("=== ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ ===")
            for source, metrics in quality_analysis.items():
                report_lines.append(f"{source}:")
                for metric, value in metrics.items():
                    report_lines.append(f"  - {metric}: {value}")
                report_lines.append("")
        
        # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
        errors = log_data.get("errors", [])
        if errors:
            report_lines.extend([
                "=== ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ ===",
                f"ç·ã‚¨ãƒ©ãƒ¼æ•°: {len(errors)}",
                ""
            ])
            
            error_types = {}
            for error in errors:
                error_type = error.get("error_type", "unknown")
                error_types[error_type] = error_types.get(error_type, 0) + 1
            
            for error_type, count in error_types.items():
                report_lines.append(f"{error_type}: {count}ä»¶")
        
        return "\n".join(report_lines)